---
title: "A1 BiocHail -- GWAS tutorial"
author: "Vincent J. Carey, stvjc at channing.harvard.edu"
date: "`r format(Sys.time(), '%B %d, %Y')`"
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{A1 BiocHail -- GWAS tutorial}
  %\VignetteEncoding{UTF-8}
output:
  BiocStyle::html_document:
    highlight: pygments
    number_sections: yes
    theme: united
    toc: yes
---

# Introduction

This document explores using Hail 0.2 with R
via basilisk.

The computations follow the
[GWAS tutorial](https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html) 
in the hail documentation.

# Acquire a slice of the 1000 genomes genotypes and annotations

This chunk takes care of importing the 1000 genomes VCF slice
distributed by the hail project.  `hail_init` uses basilisk,
which ensures that a specific version of hail and
its dependencies are available in an isolated virtual environment.
```{r getlib,message=FALSE}
library(BiocHail)
```

## Initialization, data acquisition, rendering

Here is a curiosity of R-hail interaction.  Note that
the following chunk computes `mt`, a MatrixTable
representation of 1000 genomes data, but our
attempt to print it in markdown fails.
```{r get1}
hl = hail_init()
mt = get_1kg(hl)
mt
print(mt$rows()$select()$show(5L)) # limited info
```

We can use the python syntax in a `python` R markdown
chunk to see what we want.  We use prefix `r.` to
find references defined in our R session (compiling
the vignette).
```{python abc}
r.mt.rows().select().show(5)
```

The sample IDs:
```{python ch2}
r.mt.s.show(5)
```

## Helper functions

Some methods return data
immediately useful in R.
```{r getdim}
mt$count()
```
We can thus define a function `dim` to behave with
hail MatrixTable instances
in a familiar way, along with some others.
```{r dodim}
dim.hail.matrixtable.MatrixTable = function(x) { 
  tmp = x$count()
  c(tmp[[1]], tmp[[2]]) 
}
dim(mt)
ncol.hail.matrixtable.MatrixTable = function(x) { 
 dim(x)[2]
}
nrow.hail.matrixtable.MatrixTable = function(x) { 
 dim(x)[1]
}
nrow(mt)
```
These can be useful on their own, or when calling python methods.

## Acquiring `column fields`

```{r domo}
annopath = path_1kg_annotations()
tab = hl$import_table(annopath, impute=TRUE)$key_by("Sample")
```
```{python ch3}
r.tab.describe()
r.tab.show(width=100)
```

## Adding the sample annotation to the MatrixTable; aggregation

We combine the `tab` defined above, with the MatrixTable instance,
usiny python code reaching to R via `r.`.
```{python ch4}
r.mt = r.mt.annotate_cols(pheno = r.tab[r.mt.s])
r.mt.col.describe()
```

Aggregation methods can be used to obtain contingency tables or descriptive statistics.

First, we get the frequencies of superpopulation membership:
```{r getsup}
mt$aggregate_cols(hl$agg$counter(mt$pheno$SuperPopulation))
```

Then statistics on caffeine consumption:
```{r lkcaf}
uu = mt$aggregate_cols(hl$agg$stats(mt$pheno$CaffeineConsumption))
names(uu)
uu$mean
uu$stdev
```

The significance of these aggregation functions is that the computations
are performed by Spark, on potentially huge distributed data structures.

Now we aggregate over rows (SNPs).  We'll use python directly:
```{python ch5}
from pprint import pprint
snp_counts = r.mt.aggregate_rows(r.hl.agg.counter(r.hl.Struct(ref=r.mt.alleles[0], alt=r.mt.alleles[1])))
pprint(snp_counts)
```

